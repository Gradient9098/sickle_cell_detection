{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11438567,"sourceType":"datasetVersion","datasetId":7165142}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# \n\n## TODO: \n\n1. Split into train/validation/test data\n2. Construct a testing apperatus. At minimum measure accuracy. Probably also things like F1. Maybe make a function which produces a list of the predicted labels along with a list of the true labels for comparison purposes?\n3. Optimize model parameters\n4. Experiment with simple vs augmented. See if there is anything in augmented that makes sense to remove/add.\n5. Test random/trained weights against pretrained/finetuned Alexnet weights.\n6. Make code more efficient? Interestingly, at least when I run it on Kaggle with the GPU T4 x2, CPU is the bottleneck by a decent margin. Not GPU. Very possible that CPU related code can be improved/the model can be made to train a decent bit faster.\n7. Organize/neaten up the notebook\n8. Split notebook? Into one for training/saving the model and one for loading/testing it.\n9. Model doesn't currently seem to be training. Loss is jumping back and forth in a certain range. Fix/make sure model is training. (Could potentially also be an issue with the dataset/labels/how I load them. Possible path to check if everything looks fine model side.)","metadata":{}},{"cell_type":"markdown","source":"# Define Supporting Methods","metadata":{}},{"cell_type":"markdown","source":"## Methods for loading the data","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision.transforms import v2 # PyTorch image transformations\nfrom PIL import Image # pillow library for opening images\n\nimport matplotlib.pyplot as plt\n\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset\nimport os\nimport random\nrandom.seed(12345)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:09:49.505045Z","iopub.execute_input":"2025-04-17T19:09:49.505768Z","iopub.status.idle":"2025-04-17T19:10:02.065435Z","shell.execute_reply.started":"2025-04-17T19:09:49.505732Z","shell.execute_reply":"2025-04-17T19:10:02.064849Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def get_transform(mode:str):\n\n    if mode == \"simple\":\n        # Without Augmentations\n        transform = v2.Compose([\n            v2.ToDtype(torch.float32, scale=True), \n        \tv2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n            ])\n\n    elif mode == \"augmented\":\n        # With Augmentations\n        transform = v2.Compose([\n            v2.ToDtype(torch.float32, scale=True),\n        \n            # flip image\n            v2.RandomHorizontalFlip(p=0.5),\n        \tv2.RandomVerticalFlip(p=0.5),\n        \n            # rotate image by 90 degrees 0, 1, 2, or 3 times\n            v2.RandomChoice([\n                v2.Lambda(lambda image: torch.rot90(image, 0, [1, 2])), # 90 degrees \n                v2.Lambda(lambda image: torch.rot90(image, 1, [1, 2])), # 90 degrees \n                v2.Lambda(lambda image: torch.rot90(image, 2, [1, 2])), # 180 degrees\n                v2.Lambda(lambda image: torch.rot90(image, 3, [1, 2])), # 270 degrees\n            ]),\n        \n        \tv2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n\n    else: \n        raise NotImplementedError\n\n    return transform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.066645Z","iopub.execute_input":"2025-04-17T19:10:02.066962Z","iopub.status.idle":"2025-04-17T19:10:02.073176Z","shell.execute_reply.started":"2025-04-17T19:10:02.066943Z","shell.execute_reply":"2025-04-17T19:10:02.072606Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def get_tot_files(main_dir):\n    tot_len = 0\n    for a_dir in os.walk(main_dir):\n        tot_len = tot_len + len(a_dir[2])\n    return tot_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.074111Z","iopub.execute_input":"2025-04-17T19:10:02.074407Z","iopub.status.idle":"2025-04-17T19:10:02.104403Z","shell.execute_reply.started":"2025-04-17T19:10:02.074384Z","shell.execute_reply":"2025-04-17T19:10:02.103800Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, main_dir, transform=None):\n        self.total_imgs = get_tot_files(main_dir)\n        self.healthy_imgs = get_tot_files(main_dir + \"/Healthy\")\n        self.transform = transform\n        self.main_dir = main_dir\n\n    def __len__(self):\n        return self.total_imgs\n\n    def __getitem__(self, idx):\n        if idx < self.healthy_imgs:\n            label = 0\n            sub_dir = \"Healthy\"\n            pos = idx\n        else:\n            label = 1\n            sub_dir = \"Anemic\"\n            pos = idx - self.healthy_imgs\n        \n        img_dir = os.path.join(self.main_dir, sub_dir)\n        img_name = next(os.walk(img_dir))[2][pos]\n        img_path = os.path.join(img_dir, img_name)\n        image = read_image(img_path)\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.106221Z","iopub.execute_input":"2025-04-17T19:10:02.106542Z","iopub.status.idle":"2025-04-17T19:10:02.124281Z","shell.execute_reply.started":"2025-04-17T19:10:02.106519Z","shell.execute_reply":"2025-04-17T19:10:02.123713Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Methods for creating the model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Alexnet(nn.Module):\n    def __init__(self):\n        super(Alexnet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n        self.conv3 = nn.Conv2d(32, 16, 3)\n        self.flat1 = nn.Flatten()\n        self.dense1 = nn.Linear(14400, 256)\n        self.dense2 = nn.Linear(256, 1)\n\n        self.pool1 = nn.MaxPool2d(2)\n        self.pool2 = nn.MaxPool2d(2)\n        self.pool3 = nn.MaxPool2d(2)\n    def forward(self, z):\n        out = F.relu(self.conv1(z))\n        out = self.pool1(out)\n        out = F.relu(self.conv2(out))\n        out = self.pool2(out) \n        out = F.relu(self.conv3(out))\n        out = self.pool3(out)  \n        out = self.flat1(out)\n        out = F.relu(self.dense1(out))\n        out = F.sigmoid(self.dense2(out))\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.125055Z","iopub.execute_input":"2025-04-17T19:10:02.125346Z","iopub.status.idle":"2025-04-17T19:10:02.150643Z","shell.execute_reply.started":"2025-04-17T19:10:02.125301Z","shell.execute_reply":"2025-04-17T19:10:02.150045Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.optim as optim\n\ndef training_loop(dataloader, num_epochs, device=\"cpu\", batch_size=16,\n                  optimizer=optim.AdamW, loss_fn=nn.BCELoss(), print_loss=True, lr=.001):\n    iter_list = []\n    an_loss_list = []\n    \n    an_model = Alexnet().to(device)\n    an_model.train()\n\n    an_optimizer = optimizer(an_model.parameters(), lr=lr)\n    \n    iteration = 0\n    for epoch in tqdm(range(num_epochs)):\n        for data, labels in dataloader:\n            images = data.to(device)\n            img_labels = labels.to(device)\n\n            an_model.zero_grad()\n            \n            an_loss = loss_fn(an_model(images)[:, 0], img_labels.float())\n\n            an_loss.backward()\n            an_optimizer.step()\n\n            if (iteration+1) % 200 == 0:\n                iter_list.append(iteration)\n                an_loss_list.append(an_loss)\n    \n            if print_loss:\n                print(f\"Iteration {iteration} during epoch {epoch}\")\n                print(f\"Alexnet loss: {an_loss}\")\n        \n            iteration += 1\n\n        if (epoch+1) % 5 == 0: \n            # Save the model every 5 epochs\n            torch.save(an_model.state_dict(), f'an_model_weights_{epoch}_{lr}.pth')\n\n    return iter_list, an_loss_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.151478Z","iopub.execute_input":"2025-04-17T19:10:02.151777Z","iopub.status.idle":"2025-04-17T19:10:02.168835Z","shell.execute_reply.started":"2025-04-17T19:10:02.151752Z","shell.execute_reply":"2025-04-17T19:10:02.168235Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Training the Model","metadata":{}},{"cell_type":"code","source":"labels_map = {\n    0: \"Healthy\",\n    1: \"Anemic\"\n}\n\ndevice = (\"cuda\" if torch.cuda.is_available()\n    else \"mps\" if torch.backends.mps.is_available()\n    else \"cpu\")\nprint(f\"Using {device} device.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.169625Z","iopub.execute_input":"2025-04-17T19:10:02.169891Z","iopub.status.idle":"2025-04-17T19:10:02.286103Z","shell.execute_reply.started":"2025-04-17T19:10:02.169867Z","shell.execute_reply":"2025-04-17T19:10:02.285512Z"}},"outputs":[{"name":"stdout","text":"Using cuda device.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nmy_batch_size=16\nmy_epochs = 20\nmy_lr = 1e-3\n\ndataset_path = \"/kaggle/input/anemic-rbc-dataset-resized/Anemic_RBC_dataset_resized/\"\ntraining_data = CustomDataset(dataset_path,  get_transform(\"simple\"))\ntrain_dataloader = DataLoader(training_data, shuffle=True, batch_size=my_batch_size, num_workers=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:02.286901Z","iopub.execute_input":"2025-04-17T19:10:02.287206Z","iopub.status.idle":"2025-04-17T19:10:33.804418Z","shell.execute_reply.started":"2025-04-17T19:10:02.287181Z","shell.execute_reply":"2025-04-17T19:10:33.803642Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"iter_list, an_loss_list = training_loop(train_dataloader, num_epochs=my_epochs, batch_size=my_batch_size,\n                                        lr=my_lr, device=device, print_loss = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:10:33.805382Z","iopub.execute_input":"2025-04-17T19:10:33.805702Z"}},"outputs":[{"name":"stderr","text":" 40%|████      | 8/20 [14:14<20:11, 100.95s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"an_loss_list = torch.tensor(an_loss_list, device=\"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting generator and discriminator loss vs iterations\nplt.plot(iter_list, an_loss_list, label=\"Alex Net\")\nplt.title(f\"Alexnet loss vs iterations, lr={my_lr}\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing the Model","metadata":{}},{"cell_type":"code","source":"import sklearn.metrics as metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch = 19\nmy_lr = my_lr\n\nmodel = Alexnet().to(device)\nmodel.load_state_dict(torch.load(f\"an_model_weights_{epoch}_{my_lr}.pth\", weights_only=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def results_list(model, dataloader, device=\"cpu\"):\n    pred_results = []\n    true_results = []\n    \n    for data, labels in tqdm(dataloader):\n        images = data.to(device)\n        results = model(images)\n        \n        for i in range(len(data)):\n            pred_results.append(results[i].detach().clone())\n            true_results.append(labels[i].detach().clone())\n    \n    return pred_results, true_results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred, truth = results_list(model, train_dataloader, device) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(len(pred)):\n    if pred[i] >.5:\n        pred[i] = 1\n    else:\n        pred[i] = 0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = torch.tensor(pred, device=\"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.accuracy_score(pred, truth)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OLD - We will need to modify if we would ike to keep these.","metadata":{}},{"cell_type":"code","source":"test_image = Image.open(data_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformed_test_image = transforms_augmented(test_image)\nv2.ToPILImage(transformed_test_image)\n\n# convert from (C, H, W) to (H, W, C) for displaying in matplotlib\nimg_np = transformed_test_image.permute(1, 2, 0).numpy()\n\n# display augmented image\nplt.imshow(img_np)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}